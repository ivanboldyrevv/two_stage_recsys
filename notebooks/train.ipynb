{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Create custom features. Features categories:\n",
    "- User features\n",
    "- Item features\n",
    "- Frequency features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first step: load data and prepared before training/validating/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_uri = \"postgresql+psycopg2://backend:backend@localhost:5432/app_db\"\n",
    "\n",
    "customers = pd.read_sql_table(\"customers\", postgres_uri)\n",
    "articles = pd.read_sql_table(\"articles\", postgres_uri)\n",
    "transactions = pd.read_sql_table(\"transactions\", postgres_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5407 entries, 0 to 5406\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   customer_uuid           5407 non-null   object\n",
      " 1   fn                      5407 non-null   int64 \n",
      " 2   active                  5407 non-null   int64 \n",
      " 3   club_member_status      5407 non-null   object\n",
      " 4   fashion_news_frequency  2909 non-null   object\n",
      " 5   age                     5407 non-null   int64 \n",
      " 6   postal_code             5407 non-null   object\n",
      " 7   customer_id             5407 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 338.1+ KB\n"
     ]
    }
   ],
   "source": [
    "customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13673 entries, 0 to 13672\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   article_uuid        13673 non-null  object\n",
      " 1   prod_name           13673 non-null  object\n",
      " 2   product_type_no     13673 non-null  int64 \n",
      " 3   product_type_name   13673 non-null  object\n",
      " 4   product_group_no    13673 non-null  int64 \n",
      " 5   product_group_name  13673 non-null  object\n",
      " 6   department_no       13673 non-null  int64 \n",
      " 7   department_name     13673 non-null  object\n",
      " 8   index_code          13673 non-null  object\n",
      " 9   index_name          13673 non-null  object\n",
      " 10  index_group_no      13673 non-null  int64 \n",
      " 11  index_group_name    13673 non-null  object\n",
      " 12  section_no          13673 non-null  int64 \n",
      " 13  section_name        13673 non-null  object\n",
      " 14  garment_group_no    13673 non-null  int64 \n",
      " 15  garment_group_name  13673 non-null  object\n",
      " 16  detail_desc         13673 non-null  object\n",
      " 17  article_id          13673 non-null  int64 \n",
      "dtypes: int64(7), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514251 entries, 0 to 514250\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   transaction_uuid  514251 non-null  object        \n",
      " 1   t_dat             514251 non-null  datetime64[ns]\n",
      " 2   price             514251 non-null  float64       \n",
      " 3   sales_channel_id  514251 non-null  int64         \n",
      " 4   customer_uuid     514251 non-null  object        \n",
      " 5   article_uuid      514251 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 23.5+ MB\n"
     ]
    }
   ],
   "source": [
    "transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepared uset/item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features = articles[[\n",
    "    \"article_uuid\", \"article_id\", \"product_type_no\", \"product_group_no\", \"department_no\", \"index_code\",\n",
    "    \"index_group_no\", \"section_no\", \"garment_group_no\"\n",
    "]]\n",
    "customer_features = customers[[\n",
    "    \"customer_uuid\", \"customer_id\", \"age\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\45097819.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  article_features[\"article_id\"] -= 1\n"
     ]
    }
   ],
   "source": [
    "article_features[\"article_id\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\1437132519.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customer_features[\"customer_id\"] -= 1\n"
     ]
    }
   ],
   "source": [
    "customer_features[\"customer_id\"] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create interaction matrix (user X item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = transactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions.merge(customer_features, how=\"left\", on=\"customer_uuid\")\n",
    "interactions = interactions.merge(article_features, how=\"left\", on=\"article_uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[[\"customer_id\", \"article_id\", \"t_dat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514251 entries, 0 to 514250\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   customer_id  514251 non-null  int64         \n",
      " 1   article_id   514251 non-null  int64         \n",
      " 2   t_dat        514251 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 11.8 MB\n"
     ]
    }
   ],
   "source": [
    "interactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Let's divide the data into three parts. The first part is the data for the first stage. The second part is the data for the second stage. The third is the test data for evaluating the overall model.  \n",
    "We will use time intervals. Min date: 2020-03-22; max date: 2020-09-22  \n",
    "- first stage train (2020-03-22/2020-06-22)\n",
    "- first stage validate (2020-06-22/2020-08-22)\n",
    "- second stage train (2020-06-22/2020-08-22)\n",
    "- second stage validate (2020-08-22/2020-09-11)\n",
    "- test (2020-09-11/2020-09-22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary for users from the first training sample to be in all other samples. This code seems to guarantee this condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = \"2020-03-22 00:00:00\"\n",
    "date_1 = \"2020-06-22 00:00:00\"\n",
    "date_2 = \"2020-08-22 00:00:00\" \n",
    "date_3 = \"2020-09-11 00:00:00\" \n",
    "date_4 = \"2020-09-22 00:00:00\"\n",
    "\n",
    "users_in_train = set(interactions[interactions[\"t_dat\"] <= date_1][\"customer_id\"])\n",
    "\n",
    "first_stage_train = interactions[interactions[\"t_dat\"] <= date_1]\n",
    "first_stage_validate = interactions[(interactions[\"t_dat\"] > date_1) & (interactions[\"t_dat\"] <= date_2) & (interactions[\"customer_id\"].isin(users_in_train))]\n",
    "\n",
    "second_stage_train = first_stage_validate\n",
    "second_stage_validate = interactions[(interactions[\"t_dat\"] > date_2) & (interactions[\"t_dat\"] <= date_3) & (interactions[\"customer_id\"].isin(users_in_train))]\n",
    "\n",
    "test = interactions[(interactions[\"t_dat\"] > date_3) & (interactions[\"t_dat\"] <= date_4) & (interactions[\"customer_id\"].isin(users_in_train))]\n",
    "\n",
    "\n",
    "assert len(set(first_stage_validate[\"customer_id\"]) - users_in_train) == 0\n",
    "assert len(set(second_stage_validate[\"customer_id\"]) - users_in_train) == 0\n",
    "assert len(set(test[\"customer_id\"]) - users_in_train) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert str(first_stage_train[\"t_dat\"].min()) == min_date\n",
    "assert str(first_stage_train[\"t_dat\"].max()) == date_1\n",
    "\n",
    "assert str(first_stage_validate[\"t_dat\"].min() - pd.Timedelta(days=1)) == date_1\n",
    "assert str(first_stage_validate[\"t_dat\"].max()) == date_2\n",
    "\n",
    "assert str(second_stage_validate[\"t_dat\"].min() - pd.Timedelta(days=1)) == date_2\n",
    "assert str(second_stage_validate[\"t_dat\"].max()) == date_3\n",
    "\n",
    "assert str(test[\"t_dat\"].min() - pd.Timedelta(days=1)) == date_3\n",
    "assert str(test[\"t_dat\"].max()) == date_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_stage_train length: 263965;\n",
      "first_stage_validate length: 175544;\n",
      "second_stage_train length: 175544;\n",
      "second_stage_validate length: 47794;\n",
      "test length: 20737\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"first_stage_train length: {len(first_stage_train)};\\n\"\n",
    "    f\"first_stage_validate length: {len(first_stage_validate)};\\n\"\n",
    "    f\"second_stage_train length: {len(second_stage_train)};\\n\"\n",
    "    f\"second_stage_validate length: {len(second_stage_validate)};\\n\"\n",
    "    f\"test length: {len(test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 468843;\n",
      "validate length: 24189;\n",
      "test length: 21219;\n"
     ]
    }
   ],
   "source": [
    "min_date = \"2020-03-22 00:00:00\"\n",
    "date_1 = \"2020-09-01 00:00:00\"\n",
    "date_2 = \"2020-09-11 00:00:00\"\n",
    "\n",
    "train = interactions[interactions[\"t_dat\"] <= date_1]\n",
    "validate = interactions[(interactions[\"t_dat\"] > date_1) & (interactions[\"t_dat\"] <= date_2)]\n",
    "test = interactions[(interactions[\"t_dat\"] > date_2)]\n",
    "\n",
    "\n",
    "assert len(set(validate[\"customer_id\"]) - set(train[\"customer_id\"])) == 0\n",
    "assert len(set(test[\"customer_id\"]) - set(train[\"customer_id\"])) == 0\n",
    "\n",
    "print(\n",
    "    f\"train length: {len(train)};\\n\"\n",
    "    f\"validate length: {len(validate)};\\n\"\n",
    "    f\"test length: {len(test)};\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training first stage\n",
    "Create als model which predicts user x items interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import implicit\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "from metrics import recall_at_k, precision_at_k\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from typing import List, Any, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_customers = len(customers)\n",
    "length_articles = len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_coo(interactions, users_len, items_len):\n",
    "    row = interactions[\"customer_id\"].values\n",
    "    col = interactions[\"article_id\"].values\n",
    "    data = np.ones(interactions.shape[0])\n",
    "\n",
    "    return coo_matrix((data, (row, col)), shape=(users_len, items_len), dtype=np.float32)\n",
    "\n",
    "\n",
    "def to_csr(interactions, users_len, items_len):\n",
    "    coo_matrix = to_coo(interactions, users_len, items_len)\n",
    "    csr_matrix = coo_matrix.tocsr()\n",
    "    return csr_matrix\n",
    "\n",
    "\n",
    "train_matrix = to_csr(train, length_customers, length_articles)\n",
    "validate_matrix = to_csr(validate, length_customers, length_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_vector(df, customer_id):\n",
    "    return df[df[\"customer_id\"] == customer_id][\"article_id\"].to_list()\n",
    "\n",
    "\n",
    "def estimate_metrics(model, df, k):\n",
    "    data = df.copy()\n",
    "    data[\"candidates\"] = data[\"customer_id\"].apply(lambda x: model.recommend(x, train_matrix[x], N=k)[0])\n",
    "    recall = []\n",
    "    precision = []\n",
    "    for _, actual, candidates in data.values:\n",
    "        recall.append(recall_at_k(actual, candidates, k=k))\n",
    "        precision.append(precision_at_k(actual, candidates, k=k))\n",
    "    return {\"recall\": np.mean(recall), \"precision\": np.mean(precision)}\n",
    "\n",
    "\n",
    "validate_matrix = pd.DataFrame({\"customer_id\": validate[\"customer_id\"].unique()})\n",
    "validate_matrix[\"actual\"] = validate_matrix[\"customer_id\"].apply(lambda x: items_vector(validate, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, model: implicit.als.AlternatingLeastSquares, user_item: csr_matrix):\n",
    "        self.model = model\n",
    "        self.sparse_matrix = user_item\n",
    "\n",
    "    def predict(self, context, model_input: List[int], params: Dict[str, Any] = None) -> List[list]:\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        N = params.get(\"N\", 10)\n",
    "\n",
    "        return self.model.recommend(model_input, self.sparse_matrix[model_input], N=N)\n",
    "\n",
    "    def get_raw_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 19:15:28,011] A new study created in memory with name: no-name-59e12661-6a31-481b-a53a-844cec4e45c5\n",
      "[I 2025-04-01 19:15:33,208] Trial 0 finished with value: 0.009932489050596556 and parameters: {'factors': 89, 'regularization': 0.007749916301453231, 'alpha': 2, 'iterations': 82}. Best is trial 0 with value: 0.009932489050596556.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 21.61it/s]\n",
      "2025/04/01 19:15:54 INFO mlflow.models.signature: Inferring model signature from type hints\n",
      "2025/04/01 19:15:54 INFO mlflow.models.signature: Failed to infer output type hint, setting output schema to AnyType. Invalid type hint `list`, it must include a valid element type. Type hints must be a list[...] where collection element type is one of these types: [<class 'int'>, <class 'str'>, <class 'bool'>, <class 'float'>, <class 'bytes'>, <class 'datetime.datetime'>], pydantic BaseModel subclasses, lists and dictionaries of primitive types, or typing.Any. Check https://mlflow.org/docs/latest/model/python_model.html#supported-type-hints for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run ALS w/ recall&precision at: http://localhost:5000/#/experiments/0/runs/6fc4ed3663ac4a2f9d210a4c4bcb6d8f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    factors = trial.suggest_int(\"factors\", 10, 200)\n",
    "    regularization = trial.suggest_float(\"regularization\", 1e-6, 1e-2, log=True)\n",
    "    alpha = trial.suggest_int(\"alpha\", -5, 15)\n",
    "    iterations = trial.suggest_int(\"iterations\", 5, 350)\n",
    "\n",
    "    model = implicit.als.AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=regularization,\n",
    "        alpha=alpha,\n",
    "        iterations=iterations,\n",
    "        random_state=42)\n",
    "\n",
    "    model.fit(train_matrix, show_progress=False)\n",
    "\n",
    "    return estimate_metrics(model, validate_matrix, 25)[\"recall\"]\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5, n_warmup_steps=30, interval_steps=10\n",
    "    ),\n",
    ")\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "with mlflow.start_run(run_name=\"ALS w/ recall&precision\"):\n",
    "    als_model = implicit.als.AlternatingLeastSquares()\n",
    "    als_model.fit(train_matrix)\n",
    "\n",
    "    mlflow.log_params(study.best_params)\n",
    "\n",
    "    # recall & precision @10\n",
    "    metrics = estimate_metrics(als_model, validate_matrix, 10)\n",
    "    mlflow.log_metric(\"recall_k10\", metrics[\"recall\"])\n",
    "    mlflow.log_metric(\"precision_k10\", metrics[\"precision\"])\n",
    "\n",
    "\n",
    "    xs = np.arange(100, 800, 50)\n",
    "    ys = [estimate_metrics(als_model, validate_matrix, k)[\"recall\"] for k in xs]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=ys,\n",
    "        name=\"recall\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xs,\n",
    "        y=np.gradient(ys) * 10,\n",
    "        name=\"change rate / gradient * 10\",\n",
    "        line=dict(color='red', width=2, dash='dot')\n",
    "    ))\n",
    "\n",
    "    mlflow.log_figure(fig, \"plot_artifacts/change_recall_rate.png\")\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"als_model\",\n",
    "        python_model=ALSModel(als_model, train_matrix)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ALS_Model' already exists. Creating a new version of this model...\n",
      "2025/04/01 19:16:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ALS_Model, version 3\n",
      "Created version '3' of model 'ALS_Model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1743520577914, current_stage='None', description='', last_updated_timestamp=1743520577914, name='ALS_Model', run_id='6fc4ed3663ac4a2f9d210a4c4bcb6d8f', run_link='', source='s3://mlflow/0/6fc4ed3663ac4a2f9d210a4c4bcb6d8f/artifacts/als_model', status='READY', status_message=None, tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.register_model(\n",
    "    \"runs:/6fc4ed3663ac4a2f9d210a4c4bcb6d8f/als_model\",\n",
    "    \"ALS_Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second stage train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data for train/validate CatBoost step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match candidates for second step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_feature(left, right, group_by, agg_col, feature_name):\n",
    "    return left.merge(\n",
    "        right.groupby(by=group_by)[agg_col]\\\n",
    "            .count()\n",
    "            .rename(feature_name) / 1,\n",
    "            how=\"left\",\n",
    "            on=group_by\n",
    "    )\n",
    "\n",
    "\n",
    "def match_candidates(df):\n",
    "    candidates = pd.DataFrame({\"customer_id\": df[\"customer_id\"].unique()})\n",
    "    candidates[\"candidates\"] = candidates[\"customer_id\"].apply(lambda x: als_model.recommend(x, train_matrix[x], 200)[0])\n",
    "\n",
    "    articles = candidates.apply(lambda x: pd.Series(x[\"candidates\"]), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    articles.name = \"article_id\"\n",
    "\n",
    "    return candidates.drop(\"candidates\", axis=1).join(articles)\n",
    "\n",
    "\n",
    "def merge_features(data, customer_features, article_features):\n",
    "    data = data.merge(customer_features, how=\"left\", on=\"customer_id\")\n",
    "    data = data.merge(article_features, how=\"left\", on=\"article_id\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_freq_features(data, right):\n",
    "    data = freq_feature(data, right, [\"article_id\"], \"article_uuid\", \"article_freq\")\n",
    "    data = freq_feature(data, right, [\"customer_id\", \"product_group_no\"], \"article_id\", \"product_group_freq\")\n",
    "    data = freq_feature(data, right, [\"customer_id\", \"index_code\"], \"article_id\", \"index_freq\")\n",
    "    data = freq_feature(data, right, [\"customer_id\", \"garment_group_no\"], \"article_id\", \"garment_group_freq\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = match_candidates(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_train = X_train[[\"customer_id\", \"article_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[0:, \"target\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.merge(candidates, how=\"outer\", on=[\"customer_id\", \"article_id\"])\n",
    "X_train = X_train.drop_duplicates(subset=[\"customer_id\", \"article_id\"])\n",
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1437903 entries, 0 to 1550242\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   customer_id  1437903 non-null  int64  \n",
      " 1   article_id   1437903 non-null  int64  \n",
      " 2   target       1437903 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 43.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merge_features(X_train, customer_features, article_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1437903 entries, 0 to 1437902\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   customer_id       1437903 non-null  int64  \n",
      " 1   article_id        1437903 non-null  int64  \n",
      " 2   target            1437903 non-null  float64\n",
      " 3   customer_uuid     1437903 non-null  object \n",
      " 4   age               1437903 non-null  int64  \n",
      " 5   article_uuid      1437903 non-null  object \n",
      " 6   product_type_no   1437903 non-null  int64  \n",
      " 7   product_group_no  1437903 non-null  int64  \n",
      " 8   department_no     1437903 non-null  int64  \n",
      " 9   index_code        1437903 non-null  object \n",
      " 10  index_group_no    1437903 non-null  int64  \n",
      " 11  section_no        1437903 non-null  int64  \n",
      " 12  garment_group_no  1437903 non-null  int64  \n",
      "dtypes: float64(1), int64(9), object(3)\n",
      "memory usage: 142.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514251 entries, 0 to 514250\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   transaction_uuid  514251 non-null  object        \n",
      " 1   t_dat             514251 non-null  datetime64[ns]\n",
      " 2   price             514251 non-null  float64       \n",
      " 3   sales_channel_id  514251 non-null  int64         \n",
      " 4   customer_uuid     514251 non-null  object        \n",
      " 5   article_uuid      514251 non-null  object        \n",
      " 6   customer_id       514251 non-null  int64         \n",
      " 7   age               514251 non-null  int64         \n",
      " 8   article_id        514251 non-null  int64         \n",
      " 9   product_type_no   514251 non-null  int64         \n",
      " 10  product_group_no  514251 non-null  int64         \n",
      " 11  department_no     514251 non-null  int64         \n",
      " 12  index_code        514251 non-null  object        \n",
      " 13  index_group_no    514251 non-null  int64         \n",
      " 14  section_no        514251 non-null  int64         \n",
      " 15  garment_group_no  514251 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(10), object(4)\n",
      "memory usage: 62.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_transactions = transactions.copy()\n",
    "full_transactions = full_transactions.merge(customer_features, how=\"left\", on=\"customer_uuid\")\n",
    "full_transactions = full_transactions.merge(article_features, how=\"left\", on=\"article_uuid\")\n",
    "\n",
    "full_transactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_freq_features(X_train, full_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1437903 entries, 0 to 1437902\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   customer_id         1437903 non-null  int64  \n",
      " 1   article_id          1437903 non-null  int64  \n",
      " 2   target              1437903 non-null  float64\n",
      " 3   customer_uuid       1437903 non-null  object \n",
      " 4   age                 1437903 non-null  int64  \n",
      " 5   article_uuid        1437903 non-null  object \n",
      " 6   product_type_no     1437903 non-null  int64  \n",
      " 7   product_group_no    1437903 non-null  int64  \n",
      " 8   department_no       1437903 non-null  int64  \n",
      " 9   index_code          1437903 non-null  object \n",
      " 10  index_group_no      1437903 non-null  int64  \n",
      " 11  section_no          1437903 non-null  int64  \n",
      " 12  garment_group_no    1437903 non-null  int64  \n",
      " 13  article_freq        1437903 non-null  float64\n",
      " 14  product_group_freq  1405504 non-null  float64\n",
      " 15  index_freq          1422832 non-null  float64\n",
      " 16  garment_group_freq  1359173 non-null  float64\n",
      "dtypes: float64(5), int64(9), object(3)\n",
      "memory usage: 186.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>target</th>\n",
       "      <th>customer_uuid</th>\n",
       "      <th>age</th>\n",
       "      <th>article_uuid</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_no</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>article_freq</th>\n",
       "      <th>product_group_freq</th>\n",
       "      <th>index_freq</th>\n",
       "      <th>garment_group_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>31</td>\n",
       "      <td>3421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>666b4c99-f2e6-4909-b4e2-2ed5e31e4f27</td>\n",
       "      <td>51</td>\n",
       "      <td>f943cd17-3034-4394-99ed-6cac6bfc6ae6</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>1710</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1009</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  article_id  target                         customer_uuid  \\\n",
       "8348           31        3421     1.0  666b4c99-f2e6-4909-b4e2-2ed5e31e4f27   \n",
       "\n",
       "      age                          article_uuid  product_type_no  \\\n",
       "8348   51  f943cd17-3034-4394-99ed-6cac6bfc6ae6              272   \n",
       "\n",
       "      product_group_no  department_no index_code  index_group_no  section_no  \\\n",
       "8348                 2           1710          A               1           6   \n",
       "\n",
       "      garment_group_no  article_freq  product_group_freq  index_freq  \\\n",
       "8348              1009           6.0                26.0        93.0   \n",
       "\n",
       "      garment_group_freq  \n",
       "8348                22.0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data, freq_columns, drop_columns):\n",
    "    for col_name in freq_columns:\n",
    "        data[col_name].fillna(0, inplace=True)\n",
    "    data = data.drop(columns=drop_columns)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\328287430.py:3: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "freq_columns = [\"article_freq\", \"product_group_freq\", \"index_freq\", \"garment_group_freq\"]\n",
    "drop_columns = [\"customer_uuid\", \"article_uuid\"]\n",
    "\n",
    "X_train = prepare(X_train, freq_columns, drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>target</th>\n",
       "      <th>age</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_no</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>article_freq</th>\n",
       "      <th>product_group_freq</th>\n",
       "      <th>index_freq</th>\n",
       "      <th>garment_group_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>3710</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1017</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>273</td>\n",
       "      <td>2</td>\n",
       "      <td>3608</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1021</td>\n",
       "      <td>114.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>3710</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1017</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>3611</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1021</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>1747</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1009</td>\n",
       "      <td>128.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437898</th>\n",
       "      <td>5406</td>\n",
       "      <td>13161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>1772</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1016</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437899</th>\n",
       "      <td>5406</td>\n",
       "      <td>13163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>1772</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1016</td>\n",
       "      <td>108.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437900</th>\n",
       "      <td>5406</td>\n",
       "      <td>13179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1919</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1005</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437901</th>\n",
       "      <td>5406</td>\n",
       "      <td>13299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>1939</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1009</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437902</th>\n",
       "      <td>5406</td>\n",
       "      <td>13479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1919</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1005</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1437903 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_id  article_id  target  age  product_type_no  \\\n",
       "0                  0         113     1.0   44              286   \n",
       "1                  0         131     0.0   44              273   \n",
       "2                  0         132     0.0   44              286   \n",
       "3                  0         191     0.0   44              302   \n",
       "4                  0         308     0.0   44              272   \n",
       "...              ...         ...     ...  ...              ...   \n",
       "1437898         5406       13161     1.0   25              272   \n",
       "1437899         5406       13163     1.0   25              272   \n",
       "1437900         5406       13179     0.0   25              254   \n",
       "1437901         5406       13299     0.0   25              272   \n",
       "1437902         5406       13479     0.0   25              254   \n",
       "\n",
       "         product_group_no  department_no index_code  index_group_no  \\\n",
       "0                       3           3710          B               1   \n",
       "1                       2           3608          B               1   \n",
       "2                       3           3710          B               1   \n",
       "3                       1           3611          B               1   \n",
       "4                       2           1747          D               2   \n",
       "...                   ...            ...        ...             ...   \n",
       "1437898                 2           1772          D               2   \n",
       "1437899                 2           1772          D               2   \n",
       "1437900                 0           1919          A               1   \n",
       "1437901                 2           1939          A               1   \n",
       "1437902                 0           1919          A               1   \n",
       "\n",
       "         section_no  garment_group_no  article_freq  product_group_freq  \\\n",
       "0                61              1017          17.0                 3.0   \n",
       "1                62              1021         114.0                49.0   \n",
       "2                61              1017          86.0                 3.0   \n",
       "3                62              1021         239.0                 0.0   \n",
       "4                53              1009         128.0                49.0   \n",
       "...             ...               ...           ...                 ...   \n",
       "1437898          57              1016          80.0                36.0   \n",
       "1437899          57              1016         108.0                36.0   \n",
       "1437900           2              1005          46.0                29.0   \n",
       "1437901           2              1009          53.0                36.0   \n",
       "1437902           2              1005          32.0                29.0   \n",
       "\n",
       "         index_freq  garment_group_freq  \n",
       "0              19.0                10.0  \n",
       "1              19.0                 0.0  \n",
       "2              19.0                10.0  \n",
       "3              19.0                 0.0  \n",
       "4              19.0                18.0  \n",
       "...             ...                 ...  \n",
       "1437898        18.0                12.0  \n",
       "1437899        18.0                12.0  \n",
       "1437900        52.0                16.0  \n",
       "1437901        52.0                11.0  \n",
       "1437902        52.0                16.0  \n",
       "\n",
       "[1437903 rows x 15 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[[\"target\"]]\n",
    "X_train = X_train.drop(columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(customer_id, df, k=5):\n",
    "    return df[df[\"customer_id\"] == customer_id].\\\n",
    "                sort_values(\"proba\", ascending=False).head(k)[\"article_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 19:19:23,193] A new study created in memory with name: no-name-bd9d0888-47ea-498e-a2ad-6c0625a5301b\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\1677756698.py:24: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\328287430.py:3: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n",
      "[I 2025-04-01 19:19:50,709] Trial 0 finished with value: 0.007492031349641516 and parameters: {'iterations': 277, 'max_depth': 6, 'learning_rate': 0.18948380663010458, 'l2_leaf_reg': 35.396948663924135}. Best is trial 0 with value: 0.007492031349641516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run whimsical-snail-678 at: http://localhost:5000/#/experiments/0/runs/efd07227491b4413ac2316e7888bba44\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8820\\328287430.py:3: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n",
      "2025/04/01 19:21:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run catboost/match candidates + rerank at: http://localhost:5000/#/experiments/0/runs/3169bfe1d1d043c49348138f252779b4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "def match_rerank(data, rerank_model):\n",
    "    data = match_candidates(validate)\n",
    "\n",
    "    data = merge_features(data, customer_features, article_features)\n",
    "    data = add_freq_features(data, full_transactions)\n",
    "    data = prepare(data, freq_columns, drop_columns)\n",
    "\n",
    "    data[\"proba\"] = rerank_model.predict(data, prediction_type=\"Probability\")[:, 1]\n",
    "\n",
    "    compared = pd.DataFrame({\"customer_id\": validate[\"customer_id\"].unique()})\n",
    "    compared[\"reranked\"] = compared[\"customer_id\"].apply(lambda x: rerank(x, data, 25))\n",
    "    compared[\"actual\"] = compared[\"customer_id\"].apply(lambda x: validate[validate[\"customer_id\"] == x][\"article_id\"].to_list())\n",
    "\n",
    "    return compared\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            \"objective\": \"Logloss\",\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 50, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 6, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
    "            \"task_type\": \"GPU\"\n",
    "        }\n",
    "\n",
    "        catboost_model = CatBoost(\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        catboost_model.fit(X_train, y_train, cat_features=[\"index_code\"], verbose=False)\n",
    "        candidates = match_rerank(validate, catboost_model)\n",
    "\n",
    "        recall = []\n",
    "        precision = []\n",
    "\n",
    "        for _, reranked, actual in candidates.values:\n",
    "            recall.append(recall_at_k(actual, reranked, 25))\n",
    "            precision.append(precision_at_k(actual, reranked, 25))\n",
    "\n",
    "        return np.mean(recall)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5, n_warmup_steps=30, interval_steps=10\n",
    "    )\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "with mlflow.start_run(run_name=\"catboost/match candidates + rerank\"):\n",
    "    catboost_model = CatBoost(params=study.best_params)\n",
    "    catboost_model.fit(X_train, y_train, cat_features=[\"index_code\"], verbose=False)\n",
    "\n",
    "    mlflow.log_params(study.best_params)\n",
    "\n",
    "    candidates = match_rerank(validate, catboost_model)\n",
    "\n",
    "    recall = []\n",
    "    precision = []\n",
    "\n",
    "    for _, reranked, actual in candidates.values:\n",
    "        recall.append(recall_at_k(actual, reranked, 25))\n",
    "        precision.append(precision_at_k(actual, reranked, 25))\n",
    "\n",
    "    mean_recall = np.mean(recall)\n",
    "    mean_precision = np.mean(precision)\n",
    "\n",
    "    mlflow.log_metric(\"recall\", mean_recall)\n",
    "    mlflow.log_metric(\"precision\", mean_precision)\n",
    "    \n",
    "    mlflow.catboost.log_model(\n",
    "        catboost_model,\n",
    "        artifact_path=\"catboost_model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CatBoost_Model'.\n",
      "2025/04/01 19:21:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: CatBoost_Model, version 1\n",
      "Created version '1' of model 'CatBoost_Model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1743520903964, current_stage='None', description='', last_updated_timestamp=1743520903964, name='CatBoost_Model', run_id='3169bfe1d1d043c49348138f252779b4', run_link='', source='s3://mlflow/0/3169bfe1d1d043c49348138f252779b4/artifacts/catboost_model', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.register_model(\n",
    "    \"runs:/3169bfe1d1d043c49348138f252779b4/catboost_model\",\n",
    "    \"CatBoost_Model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
